{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# scRNA-seq Foundation Model - Google Colab Training\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/yourusername/scrna-foundation-model/blob/main/notebooks/Google_Colab_Training.ipynb)\n",
    "\n",
    "Train a mini foundation model for single-cell RNA sequencing analysis using **FREE Google Colab GPU**!\n",
    "\n",
    "**Training time**: 5-15 minutes on T4 GPU (vs 2-4 hours on laptop CPU)\n",
    "\n",
    "---\n",
    "\n",
    "## Before You Start\n",
    "\n",
    "### 1. Enable GPU\n",
    "- Click **Runtime** ‚Üí **Change runtime type**\n",
    "- Select **GPU** (T4, T4 GPU, or better)\n",
    "- Click **Save**\n",
    "\n",
    "### 2. What This Notebook Does\n",
    "- ‚úÖ Installs all dependencies\n",
    "- ‚úÖ Downloads example scRNA-seq data (PBMC3k)\n",
    "- ‚úÖ Trains a foundation model\n",
    "- ‚úÖ Visualizes cell embeddings\n",
    "- ‚úÖ Saves trained model for download\n",
    "\n",
    "### 3. Costs\n",
    "- **FREE** with Google Colab free tier\n",
    "- 12-hour session limit (more than enough!)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## 1. Setup and Installation\n",
    "\n",
    "First, let's check GPU availability and install dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_gpu"
   },
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"‚úÖ GPU Available: {gpu_name}\")\n",
    "    print(f\"   Memory: {gpu_memory:.1f} GB\")\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No GPU detected!\")\n",
    "    print(\"   Go to Runtime ‚Üí Change runtime type ‚Üí Select GPU\")\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone_repo"
   },
   "outputs": [],
   "source": [
    "# Clone repository\n",
    "!git clone https://github.com/yourusername/scrna-foundation-model.git\n",
    "%cd scrna-foundation-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_deps"
   },
   "outputs": [],
   "source": [
    "# Install dependencies (takes ~2 minutes)\n",
    "!pip install -q torch torchvision\n",
    "!pip install -q scanpy anndata\n",
    "!pip install -q scikit-learn\n",
    "!pip install -q matplotlib seaborn\n",
    "!pip install -q umap-learn\n",
    "!pip install -q tqdm pyyaml omegaconf\n",
    "\n",
    "print(\"‚úÖ Installation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_section"
   },
   "source": [
    "## 2. Load and Preprocess Data\n",
    "\n",
    "We'll use the PBMC3k dataset (3,000 peripheral blood cells)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_modules"
   },
   "outputs": [],
   "source": "# Add repository to Python path (needed for Colab)\nimport sys\nimport os\n\n# Add the repository root to sys.path so we can import from src\nrepo_root = os.getcwd()\nif repo_root not in sys.path:\n    sys.path.insert(0, repo_root)\n\nprint(f\"Repository root: {repo_root}\")\nprint(f\"Python path updated: {repo_root in sys.path}\")\n\n# Imports\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom src.data.loader import download_example_dataset\nfrom src.data.preprocessor import scRNAPreprocessor\nfrom src.data.dataset import create_dataloaders\nfrom src.models.model import scRNAFoundationModel\nfrom src.training.trainer import Trainer\nfrom src.utils.visualization import plot_umap\n\nprint(\"‚úÖ Imports successful!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load_data"
   },
   "outputs": [],
   "source": [
    "# Download example dataset\n",
    "print(\"Downloading PBMC3k dataset...\")\n",
    "adata = download_example_dataset('pbmc3k', save_dir='data/raw')\n",
    "\n",
    "print(f\"\\n‚úÖ Loaded dataset:\")\n",
    "print(f\"   Cells: {adata.n_obs:,}\")\n",
    "print(f\"   Genes: {adata.n_vars:,}\")\n",
    "print(f\"   Size: {adata.X.nbytes / 1e6:.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "preprocess"
   },
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "print(\"Preprocessing data...\")\n",
    "\n",
    "preprocessor = scRNAPreprocessor(\n",
    "    min_genes=200,\n",
    "    min_cells=3,\n",
    "    max_genes=5000,\n",
    "    max_pct_mito=20,\n",
    "    target_sum=1e4,\n",
    "    n_top_genes=2000,  # Use 2000 highly variable genes\n",
    "    normalize=True,\n",
    "    log_transform=True,\n",
    "    scale=False\n",
    ")\n",
    "\n",
    "adata_processed = preprocessor.preprocess(adata, return_hvg_subset=True)\n",
    "\n",
    "print(f\"\\n‚úÖ Preprocessed data:\")\n",
    "print(f\"   Cells: {adata_processed.n_obs:,}\")\n",
    "print(f\"   Highly Variable Genes: {adata_processed.n_vars:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model_section"
   },
   "source": [
    "## 3. Create Model and Training Setup\n",
    "\n",
    "We'll create a model with ~25M parameters optimized for Colab's T4 GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_dataloaders"
   },
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "print(\"Creating dataloaders...\")\n",
    "\n",
    "train_loader, val_loader, test_loader = create_dataloaders(\n",
    "    adata_processed,\n",
    "    batch_size=64,  # Larger batch for GPU\n",
    "    train_split=0.8,\n",
    "    val_split=0.1,\n",
    "    num_workers=2,\n",
    "    expression_bins=50,\n",
    "    mask_prob=0.15,\n",
    "    use_augmentation=True\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Dataloaders created:\")\n",
    "print(f\"   Training samples: {len(train_loader.dataset):,}\")\n",
    "print(f\"   Validation samples: {len(val_loader.dataset):,}\")\n",
    "print(f\"   Test samples: {len(test_loader.dataset):,}\")\n",
    "print(f\"   Batches per epoch: {len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_model"
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "print(\"Creating model...\")\n",
    "\n",
    "model = scRNAFoundationModel(\n",
    "    n_genes=2000,\n",
    "    gene_embedding_dim=128,\n",
    "    expression_bins=50,\n",
    "    hidden_dim=256,\n",
    "    num_layers=4,\n",
    "    num_heads=8,\n",
    "    ff_dim=1024,\n",
    "    dropout=0.1,\n",
    "    use_mlm_head=True,\n",
    "    use_contrastive_head=True,\n",
    "    projection_dim=128\n",
    ")\n",
    "\n",
    "# Move to GPU\n",
    "model = model.to(device)\n",
    "\n",
    "# Count parameters\n",
    "n_params = sum(p.numel() for p in model.parameters())\n",
    "n_trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\n‚úÖ Model created:\")\n",
    "print(f\"   Total parameters: {n_params:,} ({n_params/1e6:.2f}M)\")\n",
    "print(f\"   Trainable parameters: {n_trainable:,}\")\n",
    "print(f\"   Device: {device}\")\n",
    "\n",
    "# Estimate memory\n",
    "if device == \"cuda\":\n",
    "    param_memory_mb = (n_params * 4) / (1024 ** 2)\n",
    "    print(f\"   Model size: ~{param_memory_mb:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "training_section"
   },
   "source": [
    "## 4. Train the Model\n",
    "\n",
    "Training will take approximately **5-15 minutes** on a T4 GPU.\n",
    "\n",
    "You can adjust:\n",
    "- `num_epochs`: Number of training epochs (20-50 recommended)\n",
    "- `batch_size`: Larger = faster but more memory (32-128)\n",
    "- Watch the progress bar for real-time updates!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup_training"
   },
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "config = {\n",
    "    'model': {\n",
    "        'n_genes': 2000,\n",
    "        'expression_bins': 50,\n",
    "    },\n",
    "    'training': {\n",
    "        'batch_size': 64,\n",
    "        'num_epochs': 30,  # Adjust this (20-50)\n",
    "        'gradient_accumulation_steps': 1,\n",
    "        'learning_rate': 1e-4,\n",
    "        'weight_decay': 0.01,\n",
    "        'lr_scheduler': 'cosine',\n",
    "        'warmup_steps': 500,\n",
    "        'max_grad_norm': 1.0,\n",
    "        'mlm_probability': 0.15,\n",
    "        'mlm_weight': 1.0,\n",
    "        'contrastive_weight': 0.5,\n",
    "        'contrastive_temperature': 0.07,\n",
    "        'logging_steps': 50,\n",
    "        'eval_steps': 500,\n",
    "        'save_steps': 1000,\n",
    "        'save_total_limit': 2,\n",
    "        'checkpoint_dir': 'checkpoints_colab',\n",
    "        'use_wandb': False,\n",
    "        'device': device,\n",
    "        'num_workers': 2,\n",
    "        'pin_memory': True,\n",
    "        'bf16': True if device == 'cuda' else False\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Training configuration:\")\n",
    "print(f\"  Epochs: {config['training']['num_epochs']}\")\n",
    "print(f\"  Batch size: {config['training']['batch_size']}\")\n",
    "print(f\"  Learning rate: {config['training']['learning_rate']}\")\n",
    "print(f\"  Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train_model"
   },
   "outputs": [],
   "source": [
    "# Create trainer\n",
    "from src.utils.logger import setup_logger\n",
    "\n",
    "logger = setup_logger(log_file='logs/colab_training.log')\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    config=config,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STARTING TRAINING\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Estimated time: 5-15 minutes on GPU\")\n",
    "print(f\"Watch the progress bar below...\\n\")\n",
    "\n",
    "# Train!\n",
    "trainer.train()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ TRAINING COMPLETE!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "results_section"
   },
   "source": [
    "## 5. Analyze Results\n",
    "\n",
    "Let's extract cell embeddings and visualize them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "extract_embeddings"
   },
   "outputs": [],
   "source": [
    "# Extract cell embeddings\n",
    "print(\"Extracting cell embeddings...\")\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from src.data.dataset import scRNADataset\n",
    "\n",
    "# Create dataset for all cells\n",
    "all_dataset = scRNADataset(\n",
    "    adata_processed,\n",
    "    expression_bins=50,\n",
    "    mask_prob=0.0,  # No masking for inference\n",
    "    use_augmentation=False\n",
    ")\n",
    "\n",
    "all_loader = DataLoader(all_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# Extract embeddings\n",
    "all_embeddings = []\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in all_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        \n",
    "        embeddings = model.get_cell_embeddings(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        \n",
    "        all_embeddings.append(embeddings.cpu().numpy())\n",
    "\n",
    "all_embeddings = np.vstack(all_embeddings)\n",
    "print(f\"‚úÖ Extracted embeddings: {all_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "visualize_umap"
   },
   "outputs": [],
   "source": [
    "# Visualize with UMAP\n",
    "print(\"Creating UMAP visualization...\")\n",
    "\n",
    "# Get cell type labels if available\n",
    "if 'louvain' in adata_processed.obs.columns:\n",
    "    labels = adata_processed.obs['louvain'].astype('category').cat.codes.values\n",
    "elif 'leiden' in adata_processed.obs.columns:\n",
    "    labels = adata_processed.obs['leiden'].astype('category').cat.codes.values\n",
    "else:\n",
    "    # Perform clustering\n",
    "    import scanpy as sc\n",
    "    sc.pp.neighbors(adata_processed)\n",
    "    sc.tl.leiden(adata_processed)\n",
    "    labels = adata_processed.obs['leiden'].astype('category').cat.codes.values\n",
    "\n",
    "# Plot UMAP\n",
    "fig = plot_umap(\n",
    "    embeddings=all_embeddings,\n",
    "    labels=labels,\n",
    "    title='Cell Embeddings from Foundation Model (UMAP)',\n",
    "    figsize=(12, 10)\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('cell_embeddings_umap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Visualization complete!\")\n",
    "print(\"   Saved to: cell_embeddings_umap.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clustering_metrics"
   },
   "outputs": [],
   "source": [
    "# Compute clustering metrics\n",
    "from src.training.metrics import compute_clustering_metrics\n",
    "\n",
    "print(\"Computing clustering metrics...\")\n",
    "\n",
    "metrics = compute_clustering_metrics(\n",
    "    embeddings=all_embeddings,\n",
    "    labels=labels\n",
    ")\n",
    "\n",
    "print(\"\\nüìä Clustering Performance:\")\n",
    "print(f\"   Adjusted Rand Index (ARI): {metrics['ari']:.4f}\")\n",
    "print(f\"   Normalized Mutual Info (NMI): {metrics['nmi']:.4f}\")\n",
    "print(f\"   Silhouette Score: {metrics['silhouette']:.4f}\")\n",
    "print(\"\\n   Higher is better (0-1 scale)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gene_importance"
   },
   "outputs": [],
   "source": [
    "# Analyze gene importance\n",
    "print(\"Analyzing gene importance...\")\n",
    "\n",
    "# Get a sample of cells\n",
    "sample_batch = next(iter(all_loader))\n",
    "sample_input_ids = sample_batch['input_ids'][:16].to(device)\n",
    "sample_attention_mask = sample_batch['attention_mask'][:16].to(device)\n",
    "\n",
    "# Get gene importance\n",
    "gene_importance = model.get_gene_importance(\n",
    "    input_ids=sample_input_ids,\n",
    "    attention_mask=sample_attention_mask\n",
    ")\n",
    "\n",
    "# Average across cells\n",
    "avg_importance = gene_importance.mean(dim=0).cpu().numpy()\n",
    "\n",
    "# Get top genes\n",
    "top_k = 20\n",
    "top_indices = np.argsort(avg_importance)[-top_k:][::-1]\n",
    "top_genes = [adata_processed.var_names[i] for i in top_indices]\n",
    "top_scores = avg_importance[top_indices]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(range(len(top_genes)), top_scores, color='steelblue')\n",
    "plt.yticks(range(len(top_genes)), top_genes)\n",
    "plt.xlabel('Attention Score (Importance)', fontsize=12)\n",
    "plt.title(f'Top {top_k} Most Important Genes', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('gene_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Gene importance analysis complete!\")\n",
    "print(f\"\\nTop 5 genes: {', '.join(top_genes[:5])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "save_section"
   },
   "source": [
    "## 6. Save and Download Model\n",
    "\n",
    "Save your trained model to download and use later!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "save_model"
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "import os\n",
    "\n",
    "os.makedirs('trained_models', exist_ok=True)\n",
    "\n",
    "# Save full model\n",
    "model_path = 'trained_models/scrna_foundation_model.pt'\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'model_config': config['model'],\n",
    "    'n_genes': 2000,\n",
    "    'gene_names': adata_processed.var_names.tolist()\n",
    "}, model_path)\n",
    "\n",
    "print(f\"‚úÖ Model saved to: {model_path}\")\n",
    "print(f\"   Size: {os.path.getsize(model_path) / 1e6:.1f} MB\")\n",
    "\n",
    "# Save embeddings\n",
    "np.save('trained_models/cell_embeddings.npy', all_embeddings)\n",
    "print(f\"‚úÖ Embeddings saved to: trained_models/cell_embeddings.npy\")\n",
    "\n",
    "print(\"\\nüì• To download:\")\n",
    "print(\"   1. Click folder icon on left sidebar\")\n",
    "print(\"   2. Navigate to 'trained_models/'\")\n",
    "print(\"   3. Right-click file ‚Üí Download\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_zip"
   },
   "outputs": [],
   "source": [
    "# Create a ZIP file for easy download\n",
    "!zip -r trained_model_package.zip trained_models/ cell_embeddings_umap.png gene_importance.png\n",
    "\n",
    "print(\"\\n‚úÖ Created package: trained_model_package.zip\")\n",
    "print(\"   Download this file to get everything!\")\n",
    "\n",
    "from google.colab import files\n",
    "print(\"\\nüì• Click below to download:\")\n",
    "files.download('trained_model_package.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "next_steps"
   },
   "source": [
    "## 7. Next Steps\n",
    "\n",
    "### Use Your Trained Model:\n",
    "\n",
    "```python\n",
    "# Load the model later\n",
    "checkpoint = torch.load('scrna_foundation_model.pt')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Get embeddings for new cells\n",
    "embeddings = model.get_cell_embeddings(input_ids=new_data)\n",
    "```\n",
    "\n",
    "### Try Different Configurations:\n",
    "- **Larger model**: Increase `hidden_dim`, `num_layers`\n",
    "- **More epochs**: Increase `num_epochs` to 50-100\n",
    "- **Your own data**: Upload your `.h5ad` file and use it instead of PBMC3k\n",
    "- **Fine-tuning**: Add a classification head for cell type prediction\n",
    "\n",
    "### Upload Your Own Data:\n",
    "\n",
    "```python\n",
    "# Upload file\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Load your data\n",
    "import anndata as ad\n",
    "adata = ad.read_h5ad('your_data.h5ad')\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "üéâ **Congratulations!** You've successfully:\n",
    "- ‚úÖ Trained a foundation model for scRNA-seq\n",
    "- ‚úÖ Generated cell embeddings\n",
    "- ‚úÖ Visualized results with UMAP\n",
    "- ‚úÖ Identified important genes\n",
    "- ‚úÖ Saved your trained model\n",
    "\n",
    "**Total time**: 5-15 minutes on free GPU!\n",
    "\n",
    "### Questions?\n",
    "- Check the [GitHub repository](https://github.com/yourusername/scrna-foundation-model)\n",
    "- Read the [documentation](https://github.com/yourusername/scrna-foundation-model/blob/main/README.md)\n",
    "\n",
    "### Share Your Results!\n",
    "If this was helpful, star ‚≠ê the repository on GitHub!\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "scRNA_Foundation_Model_Colab_Training.ipynb",
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}