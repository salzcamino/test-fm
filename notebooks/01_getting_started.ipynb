{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with scRNA-seq Foundation Model\n",
    "\n",
    "This notebook demonstrates the basic usage of the scRNA-seq foundation model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.data.loader import download_example_dataset\n",
    "from src.data.preprocessor import scRNAPreprocessor\n",
    "from src.data.dataset import scRNADataset\n",
    "from src.models.model import scRNAFoundationModel\n",
    "from src.utils.visualization import plot_umap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download example PBMC dataset\n",
    "adata = download_example_dataset('pbmc3k', save_dir='../data/raw')\n",
    "\n",
    "print(f\"Dataset shape: {adata.n_obs} cells × {adata.n_vars} genes\")\n",
    "print(f\"Available metadata: {list(adata.obs.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize preprocessor\n",
    "preprocessor = scRNAPreprocessor(\n",
    "    min_genes=200,\n",
    "    min_cells=3,\n",
    "    max_genes=5000,\n",
    "    max_pct_mito=20,\n",
    "    target_sum=1e4,\n",
    "    n_top_genes=2000,\n",
    "    normalize=True,\n",
    "    log_transform=True\n",
    ")\n",
    "\n",
    "# Preprocess data\n",
    "adata_processed = preprocessor.preprocess(adata, return_hvg_subset=True)\n",
    "\n",
    "print(f\"Processed dataset shape: {adata_processed.n_obs} cells × {adata_processed.n_vars} genes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "dataset = scRNADataset(\n",
    "    adata_processed,\n",
    "    expression_bins=50,\n",
    "    mask_prob=0.15,\n",
    "    use_augmentation=False\n",
    ")\n",
    "\n",
    "print(f\"Dataset size: {len(dataset)} cells\")\n",
    "\n",
    "# Get a sample\n",
    "sample = dataset[0]\n",
    "print(f\"\\nSample keys: {list(sample.keys())}\")\n",
    "for key, value in sample.items():\n",
    "    print(f\"  {key}: shape={value.shape}, dtype={value.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = scRNAFoundationModel(\n",
    "    n_genes=2000,\n",
    "    gene_embedding_dim=128,\n",
    "    expression_bins=50,\n",
    "    hidden_dim=256,\n",
    "    num_layers=4,\n",
    "    num_heads=8,\n",
    "    ff_dim=1024,\n",
    "    dropout=0.1,\n",
    "    use_mlm_head=True,\n",
    "    use_contrastive_head=True\n",
    ")\n",
    "\n",
    "# Count parameters\n",
    "n_params = sum(p.numel() for p in model.parameters())\n",
    "n_trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Total parameters: {n_params:,}\")\n",
    "print(f\"Trainable parameters: {n_trainable:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare batch\n",
    "batch_size = 16\n",
    "batch_indices = np.random.choice(len(dataset), batch_size, replace=False)\n",
    "\n",
    "input_ids = torch.stack([dataset[i]['input_ids'] for i in batch_indices])\n",
    "attention_mask = torch.stack([dataset[i]['attention_mask'] for i in batch_indices])\n",
    "\n",
    "# Forward pass\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        return_attention=True\n",
    "    )\n",
    "\n",
    "print(\"Model outputs:\")\n",
    "for key, value in outputs.items():\n",
    "    if isinstance(value, torch.Tensor):\n",
    "        print(f\"  {key}: {value.shape}\")\n",
    "    elif isinstance(value, list):\n",
    "        print(f\"  {key}: list of {len(value)} tensors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Extract Cell Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract embeddings for all cells\n",
    "all_embeddings = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i in range(0, len(dataset), 32):\n",
    "        batch_idx = list(range(i, min(i + 32, len(dataset))))\n",
    "        batch_input_ids = torch.stack([dataset[j]['input_ids'] for j in batch_idx])\n",
    "        batch_attention_mask = torch.stack([dataset[j]['attention_mask'] for j in batch_idx])\n",
    "        \n",
    "        embeddings = model.get_cell_embeddings(\n",
    "            input_ids=batch_input_ids,\n",
    "            attention_mask=batch_attention_mask\n",
    "        )\n",
    "        \n",
    "        all_embeddings.append(embeddings.cpu().numpy())\n",
    "\n",
    "all_embeddings = np.vstack(all_embeddings)\n",
    "print(f\"Embeddings shape: {all_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualize Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot UMAP\n",
    "if 'louvain' in adata_processed.obs.columns:\n",
    "    labels = adata_processed.obs['louvain'].astype('category').cat.codes.values\n",
    "else:\n",
    "    labels = None\n",
    "\n",
    "fig = plot_umap(\n",
    "    embeddings=all_embeddings,\n",
    "    labels=labels,\n",
    "    title='Cell Embeddings (UMAP)',\n",
    "    figsize=(10, 8)\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Gene Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get gene importance scores\n",
    "gene_importance = model.get_gene_importance(\n",
    "    input_ids=input_ids[:4],  # Use first 4 cells\n",
    "    attention_mask=attention_mask[:4]\n",
    ")\n",
    "\n",
    "# Average across cells\n",
    "avg_importance = gene_importance.mean(dim=0).cpu().numpy()\n",
    "\n",
    "# Get top genes\n",
    "top_k = 20\n",
    "top_indices = np.argsort(avg_importance)[-top_k:][::-1]\n",
    "top_genes = [adata_processed.var_names[i] for i in top_indices]\n",
    "top_scores = avg_importance[top_indices]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(range(len(top_genes)), top_scores)\n",
    "plt.yticks(range(len(top_genes)), top_genes)\n",
    "plt.xlabel('Importance Score')\n",
    "plt.title(f'Top {top_k} Important Genes')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Next Steps\n",
    "\n",
    "- Train the model on your data using `train.py`\n",
    "- Fine-tune for downstream tasks (cell type classification, batch correction)\n",
    "- Explore different model architectures and hyperparameters\n",
    "- Analyze attention patterns to understand gene interactions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
